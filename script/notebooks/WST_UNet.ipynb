{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from kymatio.torch import Scattering2D\n",
    "import segmentation_models_pytorch as smp\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configurazione Scattering Wavelet\n",
    "class ScatteringPreprocessor(nn.Module):\n",
    "      def __init__(self, J=2, shape=(256, 256)):\n",
    "            super().__init__()\n",
    "            self.scattering = Scattering2D(J=J, shape=shape)\n",
    "            self.J = J\n",
    "            self.shape = shape\n",
    "            \n",
    "      def forward(self, x):\n",
    "            S = self.scattering(x)\n",
    "            batch_size, channels, coeffs, h, w = S.shape\n",
    "            return S.view(batch_size, channels * coeffs, h, w)\n",
    "\n",
    "\n",
    "# 2. Architettura Custom Unet con Scattering\n",
    "class ScatteringRiverSegmenter(nn.Module):\n",
    "      def __init__(self, J=2, input_shape=(256, 256), num_classes=1):\n",
    "            super().__init__()\n",
    "            \n",
    "            # Calcolo dimensioni scattering\n",
    "            self.scattering = ScatteringPreprocessor(J=J, shape=input_shape)\n",
    "            dummy_in = torch.randn(1, 3, *input_shape)\n",
    "            dummy_out = self.scattering(dummy_in)\n",
    "            scat_channels = dummy_out.shape[1]\n",
    "            \n",
    "            # Custom Encoder-Decoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                  nn.Conv2d(scat_channels, 64, 3, padding=1),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(2),\n",
    "                  nn.Conv2d(64, 128, 3, padding=1),\n",
    "                  nn.ReLU(),\n",
    "                  nn.MaxPool2d(2)\n",
    "            )\n",
    "            \n",
    "            self.decoder = nn.Sequential(\n",
    "                  nn.ConvTranspose2d(128, 64, 2, stride=2),\n",
    "                  nn.ReLU(),\n",
    "                  nn.ConvTranspose2d(64, 32, 2, stride=2),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Conv2d(32, num_classes, 1),\n",
    "                  nn.Sigmoid()\n",
    "            )\n",
    "            \n",
    "      def forward(self, x):\n",
    "            x = self.scattering(x)\n",
    "            x = self.encoder(x)\n",
    "            x = self.decoder(x)\n",
    "            return F.interpolate(x, scale_factor=2**self.J, mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "# 3. Dataset con Augmentation\n",
    "class RiverDataset(Dataset):\n",
    "      def __init__(self, img_dir, mask_dir, scattering, transform=None):\n",
    "            self.img_paths = sorted(glob.glob(f\"{img_dir}/*.jpg\"))\n",
    "            self.mask_paths = sorted(glob.glob(f\"{mask_dir}/*.png\"))\n",
    "            self.transform = transform\n",
    "            self.scattering = scattering\n",
    "            \n",
    "            # Controllo dimensionale\n",
    "            test_img = cv2.imread(self.img_paths[0])\n",
    "            self.original_size = test_img.shape[:2]\n",
    "            \n",
    "      def __getitem__(self, idx):\n",
    "            img = cv2.cvtColor(cv2.imread(self.img_paths[idx]), cv2.COLOR_BGR2RGB)\n",
    "            mask = cv2.imread(self.mask_paths[idx], 0)\n",
    "            \n",
    "            if self.transform:\n",
    "                  augmented = self.transform(image=img, mask=mask)\n",
    "                  img = augmented['image']\n",
    "                  mask = augmented['mask']\n",
    "            \n",
    "            # Applicazione scattering\n",
    "            img_tensor = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "            with torch.no_grad():\n",
    "                  scattering_coeffs = self.scattering(img_tensor.unsqueeze(0)).squeeze()\n",
    "            \n",
    "            return scattering_coeffs, torch.from_numpy(mask).float()\n",
    "\n",
    "\n",
    "# 4. Pipeline di Training\n",
    "def train_river_segmenter():\n",
    "      # Configurazioni\n",
    "      J = 2\n",
    "      input_shape = (256, 256)\n",
    "      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "      \n",
    "      # Modello e preprocessing\n",
    "      scattering = ScatteringPreprocessor(J=J, shape=input_shape).to(device)\n",
    "      model = ScatteringRiverSegmenter(J=J, input_shape=input_shape).to(device)\n",
    "      \n",
    "      # Augmentations specifiche per drone\n",
    "      transform = A.Compose([\n",
    "            A.Resize(256, 256),\n",
    "            A.RandomRotate90(),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.GaussNoise(var_limit=(0.001, 0.005)),  # Rumore tipico da drone\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "      ])\n",
    "      \n",
    "      # Dataset e DataLoader\n",
    "      dataset = RiverDataset(\n",
    "            img_dir='path/to/images',\n",
    "            mask_dir='path/to/masks',\n",
    "            scattering=scattering,\n",
    "            transform=transform\n",
    "      )\n",
    "      \n",
    "      train_loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "      \n",
    "      # Ottimizzatore e Loss\n",
    "      optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "      loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=False)\n",
    "      \n",
    "      # Training Loop\n",
    "      for epoch in range(50):\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "                  coeffs, masks = batch\n",
    "                  coeffs, masks = coeffs.to(device), masks.to(device)\n",
    "                  \n",
    "                  optimizer.zero_grad()\n",
    "                  outputs = model(coeffs)\n",
    "                  loss = loss_fn(outputs, masks.unsqueeze(1))\n",
    "                  loss.backward()\n",
    "                  optimizer.step()\n",
    "            \n",
    "            # Validazione e logging (aggiungere secondo dataset)\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item():.4f}')\n",
    "      \n",
    "      # Salvataggio modello\n",
    "      torch.save(model.state_dict(), 'river_segmenter_scattering.pth')\n",
    "\n",
    "\n",
    "# 5. Inference con Post-Processing\n",
    "class RiverSegmenter:\n",
    "      def __init__(self, model_path, J=2, device='cuda'):\n",
    "            self.device = device\n",
    "            self.scattering = ScatteringPreprocessor(J=J, shape=(256, 256)).to(device)\n",
    "            self.model = ScatteringRiverSegmenter(J=J).to(device)\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "            self.model.eval()\n",
    "            \n",
    "            self.transform = A.Compose([\n",
    "                  A.Resize(256, 256),\n",
    "                  A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            ])\n",
    "      \n",
    "      def predict(self, image_path):\n",
    "            img = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "            original_size = img.shape[:2]\n",
    "            \n",
    "            # Preprocessing\n",
    "            augmented = self.transform(image=img)\n",
    "            img_tensor = torch.from_numpy(augmented['image']).permute(2, 0, 1).float()\n",
    "            \n",
    "            # Scattering e predizione\n",
    "            with torch.no_grad():\n",
    "                  coeffs = self.scattering(img_tensor.unsqueeze(0).to(self.device))\n",
    "                  pred = self.model(coeffs).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Post-processing\n",
    "            mask = cv2.resize(pred, original_size[::-1])\n",
    "            binary_mask = (mask > 0.5).astype(np.uint8)\n",
    "            \n",
    "            # Pulizia morfologica\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "            cleaned = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "            return cleaned * 255\n",
    "\n",
    "\n",
    "# Utilizzo\n",
    "if __name__ == \"__main__\":\n",
    "      # Addestramento\n",
    "      train_river_segmenter()\n",
    "      \n",
    "      # Inference\n",
    "      segmenter = RiverSegmenter('river_segmenter_scattering.pth')\n",
    "      mask = segmenter.predict('drone_image.jpg')\n",
    "      cv2.imwrite('river_mask.png', mask)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
